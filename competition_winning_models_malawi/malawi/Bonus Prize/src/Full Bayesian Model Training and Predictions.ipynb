{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.training_models import (\n",
    "    infer, cv_train_model,\n",
    "    lr_cv, nn_cv, rf_cv, lgb_cv, xgb_cv\n",
    ")\n",
    "\n",
    "from modules.training_utils import (\n",
    "    get_indiv_important_cols, round_float_to, get_round_num,\n",
    "    get_opt_val_seeds, make_country_sub, timing\n",
    ")\n",
    "\n",
    "from modules.training_optimizers import (\n",
    "    get_optimized_weighted_preds_for\n",
    ")\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename='output.logs', format='%(asctime)s: %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import pickle as cPickle\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from collections import Counter\n",
    "from bayes_opt import BayesianOptimization\n",
    "from hashlib import md5\n",
    "\n",
    "\n",
    "def vprint(x):\n",
    "    if log_verbose:\n",
    "        logging.info(x)\n",
    "\n",
    "\n",
    "def prepare_test_data(X_hhold_test=None, X_indiv_cat_test=None, X_train=None, X_val=None, fill='mean'):\n",
    "    # http://fastml.com/how-to-use-pd-dot-get-dummies-with-the-test-set/\n",
    "    '''\n",
    "    X_hhold_test: equivalent to <country_code>_hhold_test\n",
    "    X_indiv_cat_test: equivalent to <country_code>_indiv_cat_test\n",
    "    X_train: corresponding training dataset\n",
    "    '''\n",
    "\n",
    "    if X_val is None:\n",
    "        test_index = X_hhold_test.index\n",
    "        X_test = pd.concat([X_hhold_test, X_indiv_cat_test], axis=1)\n",
    "        X_test = X_test.loc[test_index]\n",
    "    else:\n",
    "        X_test = X_val\n",
    "\n",
    "    for col in X_train.columns.difference(X_test.columns):\n",
    "        if fill == 'mean':\n",
    "            X_test[col] = X_train[col].mean()\n",
    "        elif fill == None:\n",
    "            X_test[col] = np.nan\n",
    "        else:\n",
    "            raise ValueError('Unknow fill method!')\n",
    "\n",
    "    X_test = X_test[X_train.columns]\n",
    "\n",
    "    if fill == 'mean':\n",
    "        X_test = X_test.fillna(X_train.mean())\n",
    "    elif fill == None:\n",
    "        # Do nothing since missing data is NaN already.\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError('Unknow fill method!')\n",
    "\n",
    "    return X_test\n",
    "\n",
    "\n",
    "def get_train_X_y(indiv_corr_thresh):\n",
    "    '''\n",
    "    hhold_train, indiv_train, indiv_cat_train, and country_code are global variables!\n",
    "    '''\n",
    "    indiv_sample_cols = get_indiv_important_cols(indiv_train, indiv_cat_train, country_code, min_corr_val=indiv_corr_thresh)\n",
    "\n",
    "    X_train = hhold_train.loc[indiv_cat_train.index].drop('poor', axis=1)\n",
    "    y_train = np.ravel(hhold_train.loc[indiv_cat_train.index].poor)\n",
    "\n",
    "    X_train = pd.concat([X_train, indiv_cat_train[indiv_sample_cols]], axis=1)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "def build_data_subset(indiv_corr_thresh, opt_val_seed=1029):\n",
    "    if indiv_corr_thresh >= 0:\n",
    "        X_train, y_train = get_train_X_y(indiv_corr_thresh=indiv_corr_thresh)\n",
    "        X_train, X_opt_val, y_train, y_opt_val = train_test_split(\n",
    "           X_train, y_train, test_size=0.05, random_state=opt_val_seed, stratify=y_train\n",
    "        )\n",
    "    else:\n",
    "        X_train, y_train = get_train_X_y(indiv_corr_thresh=0)\n",
    "        X_train, X_opt_val, y_train, y_opt_val = train_test_split(\n",
    "           X_train, y_train, test_size=0.05, random_state=42, stratify=y_train\n",
    "        )\n",
    "        X_train, X_feat_sel, y_train, y_feat_sel = train_test_split(\n",
    "            X_train, y_train, test_size=0.05, random_state=opt_val_seed, stratify=y_train\n",
    "        )\n",
    "\n",
    "        feat_C = 10. ** (round(abs(indiv_corr_thresh), 1) * 10)\n",
    "\n",
    "        br = LogisticRegression(C=feat_C, penalty='l1', random_state=42)\n",
    "        br.fit(X_feat_sel, y_feat_sel)\n",
    "\n",
    "        important_feats = X_feat_sel.columns[br.coef_[0] > 0]\n",
    "        X_train = X_train[important_feats]\n",
    "        \n",
    "    X_train = X_train[X_train.columns[X_train.std() != 0]]\n",
    "    vprint('Using {} features :: opt_val_seed {}...'.format(X_train.shape[1], opt_val_seed))\n",
    "    \n",
    "    return (X_train, y_train), (X_opt_val, y_opt_val)\n",
    "\n",
    "\n",
    "def bayesian_optimize_model(country_code, model_type, tunable_params=None, num_iter=50, init_points=0):\n",
    "    global round_num\n",
    "    global is_training\n",
    "\n",
    "    round_num = 0\n",
    "    is_training = True\n",
    "\n",
    "    store_fname = 'xgbBO_{}_res_{}_optimization_{}.dict'.format(country_code, model_type, datetime.now())\n",
    "    logging.info('Bayesian optimization results will be stored in {} after training...'.format(store_fname))\n",
    "\n",
    "    if tunable_params is None:\n",
    "        if model_type == 'xgb':\n",
    "            tunable_params = {\n",
    "                'indiv_corr_thresh': (0, 0.3),\n",
    "                'colsample_bytree': (0.2, 1),\n",
    "                'max_depth': (2, 6),\n",
    "                'subsample': (0.2, 1),\n",
    "                'gamma': (0, 2),\n",
    "                'scale_pos_weight': (0, 1),\n",
    "            }\n",
    "        elif model_type == 'lr':\n",
    "            tunable_params = {\n",
    "                'indiv_corr_thresh': (-0.9, 0.3),\n",
    "                'C': (0.001, 0.6),\n",
    "            }\n",
    "        elif model_type == 'lgb':\n",
    "            tunable_params = {\n",
    "                'indiv_corr_thresh': (0, 0.4),\n",
    "                'num_leaves': (4, 64),\n",
    "                'colsample_bytree' : (0.2, 1),\n",
    "                'subsample' : (0.2, 1),\n",
    "                'min_child_samples': (2, 120),\n",
    "                'scale_pos_weight': (0, 1),\n",
    "            }\n",
    "        elif model_type == 'nn':\n",
    "            tunable_params = {\n",
    "                'indiv_corr_thresh': (-0.9, 0.3),\n",
    "                'l1_num': (0, 100),\n",
    "                'l2_num' : (0, 100),\n",
    "                'l3_num' : (0, 100),\n",
    "                'alpha' : (0.005, 0.1),\n",
    "            }\n",
    "\n",
    "        elif model_type == 'rf':\n",
    "            tunable_params = {\n",
    "                'indiv_corr_thresh': (0, 0.4),\n",
    "                'max_depth': (2, 20),\n",
    "                'min_samples_split' : (2, 20),\n",
    "                'min_samples_leaf' : (2, 20),\n",
    "            }\n",
    "\n",
    "    if model_type == 'xgb':\n",
    "        model_predict = xgb_predict\n",
    "    elif model_type == 'lr':\n",
    "        model_predict = lr_predict\n",
    "    elif model_type == 'lgb':\n",
    "        model_predict = lgb_predict\n",
    "    elif model_type == 'nn':\n",
    "        model_predict = nn_predict\n",
    "    elif model_type == 'rf':\n",
    "        model_predict = rf_predict\n",
    "\n",
    "    modelBO = BayesianOptimization(\n",
    "        model_predict, tunable_params, verbose=bayes_opt_verbose\n",
    "    )\n",
    "\n",
    "    modelBO.maximize(init_points=init_points, n_iter=num_iter, acq=\"poi\", xi=0.1)\n",
    "\n",
    "    with open('./bayesian-opts-res/{:0.5}'.format(-modelBO.res['max']['max_val']) + '-' + store_fname, 'wb') as fl:\n",
    "        cPickle.dump(modelBO.res, fl)\n",
    "\n",
    "    return modelBO\n",
    "\n",
    "\n",
    "def infer_test_val(\n",
    "    model_id, res_name, X_train, y_oof_preds,\n",
    "    X_hhold_test, X_indiv_cat_test,\n",
    "    X_val, fill_type, classifiers\n",
    "):\n",
    "    X_test = prepare_test_data(\n",
    "        X_hhold_test=X_hhold_test, X_indiv_cat_test=X_indiv_cat_test,\n",
    "        X_train=X_train, fill=fill_type\n",
    "    )\n",
    "\n",
    "    test_payload = infer(model_id, res_name, X_test, fill_type, classifiers)\n",
    "\n",
    "    payload = {\n",
    "        'train': {\n",
    "            '{}_{}'.format(model_id, res_name): y_oof_preds,\n",
    "            'index': X_train.index\n",
    "        },\n",
    "        'test': test_payload\n",
    "    }\n",
    "\n",
    "    if X_val is not None:\n",
    "        X_val = prepare_test_data(\n",
    "            X_train=X_train, X_val=X_val, fill=fill_type\n",
    "        )\n",
    "        val_payload = infer(model_id, res_name, X_val, fill_type, classifiers)\n",
    "\n",
    "        payload['val'] = val_payload\n",
    "\n",
    "    return payload\n",
    "\n",
    "\n",
    "def lr_predict(\n",
    "    indiv_corr_thresh,\n",
    "    C,\n",
    "    class_weight=None,\n",
    "    X_test=None,\n",
    "    X_val=None,\n",
    "    res_name=None,\n",
    "    opt_val_seed=None,\n",
    "    model_id='lr',\n",
    "    cv_func=lr_cv,\n",
    "    fill_type='mean'\n",
    "):\n",
    "    indiv_corr_thresh = round(indiv_corr_thresh, 2)\n",
    "\n",
    "    if opt_val_seed is None:\n",
    "        global round_num\n",
    "        global opt_val_seeds\n",
    "        opt_val_seed = opt_val_seeds[round_num]\n",
    "\n",
    "    (X_train, y_train), (X_opt_val, y_opt_val) = build_data_subset(\n",
    "        indiv_corr_thresh=indiv_corr_thresh, opt_val_seed=opt_val_seed\n",
    "    )\n",
    "\n",
    "    X_opt_val = prepare_test_data(\n",
    "        X_train=X_train, X_val=X_opt_val, fill=fill_type\n",
    "    )\n",
    "\n",
    "    params = {}\n",
    "    params['C'] = max(round(C, 2), 0.001)\n",
    "    if class_weight is not None:\n",
    "        params['class_weight'] = {\n",
    "            0: 1.0,\n",
    "            1: round(class_weight, 2),\n",
    "        } if class_weight < 0.5 else None\n",
    "\n",
    "    params['penalty'] = 'l1'\n",
    "\n",
    "    y_oof_preds, classifiers, opt_val_loss = cv_train_model(\n",
    "        X_train, y_train, X_opt_val, y_opt_val, params,\n",
    "        model_id=model_id, res_name=res_name, cv_func=cv_func,\n",
    "        fill_type=fill_type, cv_split=10\n",
    "    )\n",
    "\n",
    "    if X_test is not None:\n",
    "        payload = infer_test_val(\n",
    "            model_id=model_id, res_name=res_name,\n",
    "            X_train=X_train, y_oof_preds=y_oof_preds,\n",
    "            X_hhold_test=hhold_test, X_indiv_cat_test=indiv_cat_test,\n",
    "            X_val=X_val,\n",
    "            fill_type=fill_type,\n",
    "            classifiers=classifiers\n",
    "        )\n",
    "\n",
    "        if is_training:\n",
    "            round_num += 1\n",
    "        return payload\n",
    "    else:\n",
    "        if is_training:\n",
    "            round_num += 1\n",
    "        return -opt_val_loss\n",
    "\n",
    "\n",
    "def nn_predict(\n",
    "    indiv_corr_thresh,\n",
    "    l1_num,\n",
    "    l2_num,\n",
    "    alpha,\n",
    "    l3_num=1,\n",
    "    X_test=None,\n",
    "    X_val=None,\n",
    "    res_name=None,\n",
    "    opt_val_seed=None,\n",
    "    model_id='nn',\n",
    "    cv_func=nn_cv,\n",
    "    fill_type='mean'\n",
    "):\n",
    "    indiv_corr_thresh = round(indiv_corr_thresh, 2)\n",
    "\n",
    "    if opt_val_seed is None:\n",
    "        global round_num\n",
    "        global opt_val_seeds\n",
    "        opt_val_seed = opt_val_seeds[round_num]\n",
    "\n",
    "    (X_train, y_train), (X_opt_val, y_opt_val) = build_data_subset(\n",
    "        indiv_corr_thresh=indiv_corr_thresh, opt_val_seed=opt_val_seed\n",
    "    )\n",
    "\n",
    "    X_opt_val = prepare_test_data(\n",
    "        X_train=X_train, X_val=X_opt_val, fill=fill_type\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        'hidden_layer_sizes': (50, 20, 1),\n",
    "        'alpha': 0.01,\n",
    "        'max_iter': 1000,\n",
    "        'early_stopping': True,\n",
    "        'random_state': 1029\n",
    "    }\n",
    "\n",
    "    params['alpha'] = round(alpha, 2)\n",
    "    params['hidden_layer_sizes'] = (get_round_num(l1_num, 10), get_round_num(l2_num, 10), get_round_num(l3_num, 5))\n",
    "\n",
    "    y_oof_preds, classifiers, opt_val_loss = cv_train_model(\n",
    "        X_train, y_train, X_opt_val, y_opt_val, params,\n",
    "        model_id=model_id, res_name=res_name, cv_func=cv_func,\n",
    "        fill_type=fill_type, cv_split=10\n",
    "    )\n",
    "\n",
    "    if X_test is not None:\n",
    "        payload = infer_test_val(\n",
    "            model_id=model_id, res_name=res_name,\n",
    "            X_train=X_train, y_oof_preds=y_oof_preds,\n",
    "            X_hhold_test=hhold_test, X_indiv_cat_test=indiv_cat_test,\n",
    "            X_val=X_val,\n",
    "            fill_type=fill_type,\n",
    "            classifiers=classifiers\n",
    "        )\n",
    "\n",
    "        if is_training:\n",
    "            round_num += 1\n",
    "        return payload\n",
    "    else:\n",
    "        if is_training:\n",
    "            round_num += 1\n",
    "        return -opt_val_loss\n",
    "\n",
    "\n",
    "def rf_predict(\n",
    "    indiv_corr_thresh,\n",
    "    max_depth,\n",
    "    min_samples_split,\n",
    "    min_samples_leaf,\n",
    "    X_test=None,\n",
    "    X_val=None,\n",
    "    res_name=None,\n",
    "    opt_val_seed=None,\n",
    "    model_id='rf',\n",
    "    cv_func=rf_cv,\n",
    "    fill_type='mean'\n",
    "):\n",
    "    indiv_corr_thresh = round(indiv_corr_thresh, 2)\n",
    "\n",
    "    if opt_val_seed is None:\n",
    "        global round_num\n",
    "        global opt_val_seeds\n",
    "        opt_val_seed = opt_val_seeds[round_num]\n",
    "\n",
    "    (X_train, y_train), (X_opt_val, y_opt_val) = build_data_subset(\n",
    "        indiv_corr_thresh=indiv_corr_thresh, opt_val_seed=opt_val_seed\n",
    "    )\n",
    "\n",
    "    X_opt_val = prepare_test_data(\n",
    "        X_train=X_train, X_val=X_opt_val, fill=fill_type\n",
    "    )\n",
    "\n",
    "    params = dict(\n",
    "        max_depth=20, min_samples_split=20, min_samples_leaf=10, n_jobs=7, random_state=1029\n",
    "    )\n",
    "\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['min_samples_split'] = get_round_num(min_samples_split, 2)\n",
    "    params['min_samples_leaf'] = get_round_num(min_samples_leaf, 2)\n",
    "\n",
    "    y_oof_preds, classifiers, opt_val_loss = cv_train_model(\n",
    "        X_train, y_train, X_opt_val, y_opt_val, params,\n",
    "        model_id=model_id, res_name=res_name, cv_func=cv_func,\n",
    "        fill_type=fill_type, cv_split=10\n",
    "    )\n",
    "\n",
    "    if X_test is not None:\n",
    "        payload = infer_test_val(\n",
    "            model_id=model_id, res_name=res_name,\n",
    "            X_train=X_train, y_oof_preds=y_oof_preds,\n",
    "            X_hhold_test=hhold_test, X_indiv_cat_test=indiv_cat_test,\n",
    "            X_val=X_val,\n",
    "            fill_type=fill_type,\n",
    "            classifiers=classifiers\n",
    "        )\n",
    "\n",
    "        if is_training:\n",
    "            round_num += 1\n",
    "        return payload\n",
    "    else:\n",
    "        if is_training:\n",
    "            round_num += 1\n",
    "        return -opt_val_loss\n",
    "\n",
    "\n",
    "def lgb_predict(\n",
    "    indiv_corr_thresh,\n",
    "    num_leaves,\n",
    "    colsample_bytree,\n",
    "    subsample,\n",
    "    min_child_samples,\n",
    "    scale_pos_weight,\n",
    "    subsample_for_bin=None,\n",
    "    X_test=None,\n",
    "    X_val=None,\n",
    "    res_name=None,\n",
    "    opt_val_seed=None,\n",
    "    model_id='lgb',\n",
    "    cv_func=lgb_cv,\n",
    "    fill_type='mean'\n",
    "):\n",
    "    indiv_corr_thresh = round(indiv_corr_thresh, 2)\n",
    "\n",
    "    if opt_val_seed is None:\n",
    "        global round_num\n",
    "        global opt_val_seeds\n",
    "        opt_val_seed = opt_val_seeds[round_num]\n",
    "\n",
    "    (X_train, y_train), (X_opt_val, y_opt_val) = build_data_subset(\n",
    "        indiv_corr_thresh=indiv_corr_thresh, opt_val_seed=opt_val_seed\n",
    "    )\n",
    "\n",
    "    X_opt_val = prepare_test_data(\n",
    "        X_train=X_train, X_val=X_opt_val, fill=fill_type\n",
    "    )\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'max_depth' : -1,\n",
    "        'objective': 'binary',\n",
    "        'learning_rate': 0.05,\n",
    "        'subsample_freq': 1,\n",
    "        'scale_pos_weight': 1,\n",
    "        'metric' : 'binary_error'\n",
    "    }\n",
    "\n",
    "    params['colsample_bytree'] = max(min(round(colsample_bytree, 2), 1), 0)\n",
    "    params['subsample'] = max(min(round(subsample, 2), 1), 0)\n",
    "    params['num_leaves'] = int(num_leaves)\n",
    "    params['min_child_samples'] = int(min_child_samples)\n",
    "    params['subsample_for_bin'] = int(subsample_for_bin) if subsample_for_bin is not None else 200000\n",
    "\n",
    "    params['learning_rate'] = 0.1\n",
    "    params['n_estimators'] = 10000\n",
    "    params['objective'] = 'binary'\n",
    "    params['random_state'] = 1029\n",
    "    params['n_jobs'] = 7\n",
    "    params['silent'] = True\n",
    "\n",
    "    scale_pos_weight = 1 if scale_pos_weight > 0.5 else 1.0 * sum(y_train < 0.5) / sum(y_train > 0.5)\n",
    "    params['scale_pos_weight'] = scale_pos_weight\n",
    "\n",
    "    y_oof_preds, classifiers, opt_val_loss = cv_train_model(\n",
    "        X_train, y_train, X_opt_val, y_opt_val, params,\n",
    "        model_id=model_id, res_name=res_name, cv_func=cv_func,\n",
    "        fill_type=fill_type, cv_split=10\n",
    "    )\n",
    "\n",
    "    if X_test is not None:\n",
    "        payload = infer_test_val(\n",
    "            model_id=model_id, res_name=res_name,\n",
    "            X_train=X_train, y_oof_preds=y_oof_preds,\n",
    "            X_hhold_test=hhold_test, X_indiv_cat_test=indiv_cat_test,\n",
    "            X_val=X_val,\n",
    "            fill_type=fill_type,\n",
    "            classifiers=classifiers\n",
    "        )\n",
    "\n",
    "        if is_training:\n",
    "            round_num += 1\n",
    "        return payload\n",
    "    else:\n",
    "        if is_training:\n",
    "            round_num += 1\n",
    "        return -opt_val_loss\n",
    "\n",
    "\n",
    "def xgb_predict(\n",
    "    indiv_corr_thresh,\n",
    "    colsample_bytree,\n",
    "    max_depth,\n",
    "    subsample,\n",
    "    gamma,\n",
    "    scale_pos_weight,\n",
    "    X_test=None,\n",
    "    X_val=None,\n",
    "    res_name=None,\n",
    "    opt_val_seed=None,\n",
    "    model_id='xgb',\n",
    "    cv_func=xgb_cv,\n",
    "    fill_type=None\n",
    "):\n",
    "    '''\n",
    "    DMatrix params\n",
    "    - weight\n",
    "    - missing (-999)\n",
    "\n",
    "    xgboost params\n",
    "    max_depth\n",
    "    min_child_weight\n",
    "    gamma -> minimum loss reduction required to make a further partition on a leaf node of the tree. The larger, the more conservative the algorithm will be.\n",
    "    subsample -> proportion of data\n",
    "    colsample_bytree -> proportion of columns used in each tree\n",
    "    max_delta_step -> for imbalanced use finite value, e.g., 1\n",
    "\n",
    "    Decrease eta and increase nrounds if overfitting is observed.\n",
    "    '''\n",
    "    indiv_corr_thresh = round(indiv_corr_thresh, 2)\n",
    "\n",
    "    if opt_val_seed is None:\n",
    "        global round_num\n",
    "        global opt_val_seeds\n",
    "        opt_val_seed = opt_val_seeds[round_num]\n",
    "\n",
    "    (X_train, y_train), (X_opt_val, y_opt_val) = build_data_subset(\n",
    "        indiv_corr_thresh=indiv_corr_thresh, opt_val_seed=opt_val_seed\n",
    "    )\n",
    "\n",
    "    X_opt_val = prepare_test_data(\n",
    "        X_train=X_train, X_val=X_opt_val, fill=fill_type\n",
    "    )\n",
    "    \n",
    "    params = {}\n",
    "    params['colsample_bytree'] = max(min(round(colsample_bytree, 2), 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['subsample'] = max(min(round(subsample, 2), 1), 0)\n",
    "    params['gamma'] = max(round(gamma, 2), 0)\n",
    "    params['learning_rate'] = 0.2\n",
    "    params['n_estimators'] = 10000\n",
    "    params['objective'] = 'binary:logistic'\n",
    "    params['random_state'] = 1029\n",
    "    params['n_jobs'] = 7\n",
    "    params['silent'] = True\n",
    "\n",
    "    scale_pos_weight = 1 if scale_pos_weight > 0.5 else 1.0 * sum(y_train < 0.5) / sum(y_train > 0.5)\n",
    "    params['scale_pos_weight'] = scale_pos_weight\n",
    "\n",
    "    y_oof_preds, classifiers, opt_val_loss = cv_train_model(\n",
    "        X_train, y_train, X_opt_val, y_opt_val, params,\n",
    "        model_id=model_id, res_name=res_name, cv_func=cv_func,\n",
    "        fill_type=fill_type, cv_split=10\n",
    "    )\n",
    "\n",
    "    if X_test is not None:\n",
    "        payload = infer_test_val(\n",
    "            model_id=model_id, res_name=res_name,\n",
    "            X_train=X_train, y_oof_preds=y_oof_preds,\n",
    "            X_hhold_test=hhold_test, X_indiv_cat_test=indiv_cat_test,\n",
    "            X_val=X_val,\n",
    "            fill_type=fill_type,\n",
    "            classifiers=classifiers\n",
    "        )\n",
    "\n",
    "        if is_training:\n",
    "            round_num += 1\n",
    "        return payload\n",
    "    else:\n",
    "        if is_training:\n",
    "            round_num += 1\n",
    "        return -opt_val_loss\n",
    "\n",
    "\n",
    "def predict_from_opt(country_code, model_type, num_params=10, use_latest=False, default_dir='./bayesian-opts-res/'):\n",
    "    global is_training\n",
    "    is_training = False\n",
    "\n",
    "    candidate_fnames = sorted(glob.glob(os.path.join(default_dir, '*-*_{}_res_{}_*_*'.format(country_code, model_type))))\n",
    "\n",
    "    if use_latest:\n",
    "        fname = max(candidate_fnames, key=os.path.getctime)\n",
    "    else:\n",
    "        fname = candidate_fnames[0]\n",
    "\n",
    "    vprint(fname)\n",
    "\n",
    "    with open(fname, 'rb') as fl:\n",
    "        res = cPickle.load(fl)\n",
    "\n",
    "    if model_type == 'xgb':\n",
    "        model_predict = xgb_predict\n",
    "    elif model_type == 'lr':\n",
    "        model_predict = lr_predict\n",
    "    elif model_type == 'lgb':\n",
    "        model_predict = lgb_predict\n",
    "    elif model_type == 'nn':\n",
    "        model_predict = nn_predict\n",
    "    elif model_type == 'rf':\n",
    "        model_predict = rf_predict\n",
    "\n",
    "    res_df = pd.DataFrame(res['all'])\n",
    "    top_res = res_df['values'].argsort().iloc[-num_params:]\n",
    "    num_round_index = top_res.values[::-1]\n",
    "    params = res_df.loc[top_res.values[::-1]]['params']\n",
    "\n",
    "    model_test_preds = pd.DataFrame()\n",
    "    model_train_preds = pd.DataFrame()\n",
    "\n",
    "    for res_name, (nm_rnd, param) in enumerate(zip(num_round_index, params)):\n",
    "        opt_val_seed = opt_val_seeds[nm_rnd]\n",
    "        r = model_predict(X_test=True, opt_val_seed=opt_val_seed, res_name=res_name, **param)\n",
    "\n",
    "        train_preds = pd.DataFrame(index=r['train']['index'])\n",
    "        train_preds['{}_{}'.format(model_type, res_name)] = r['train']['{}_{}'.format(model_type, res_name)]\n",
    "\n",
    "        test_preds = r['test']['{}_{}'.format(model_type, res_name)]\n",
    "\n",
    "        if model_test_preds.empty:\n",
    "            model_test_preds = test_preds\n",
    "        else:\n",
    "            model_test_preds = pd.concat([model_test_preds, test_preds], axis=1)\n",
    "\n",
    "        if model_train_preds.empty:\n",
    "            model_train_preds = train_preds\n",
    "        else:\n",
    "            model_train_preds = pd.concat([model_train_preds, train_preds], axis=1)\n",
    "\n",
    "    return model_test_preds, model_train_preds\n",
    "\n",
    "\n",
    "def load_data(country_code, data_part='train'):\n",
    "    hhold = os.path.join(MWI_DATA_DIR, '{}_aligned_hhold_{}.csv'.format(country_code, data_part))\n",
    "    indiv = os.path.join(MWI_DATA_DIR, '{}_aligned_indiv_{}.csv'.format(country_code, data_part))\n",
    "\n",
    "    hhold = pd.read_csv(hhold, index_col='id')\n",
    "    indiv = pd.read_csv(indiv, index_col=['id', 'iid'])\n",
    "\n",
    "    return hhold, indiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directories\n",
    "DATA_DIR = os.path.join('..', 'data')\n",
    "MWI_DATA_DIR = os.path.join('..', '..', 'data', 'raw_mwi')\n",
    "SUBMISSION_DIR = os.path.join('..', 'submission')\n",
    "BAYESIAN_OPTS_DIR = './bayesian-opts-res'\n",
    "BAYESIAN_OPTS_TEST_DIR = os.path.join(BAYESIAN_OPTS_DIR, 'bayesian-opt-test-preds')\n",
    "\n",
    "# Setup directories\n",
    "if not os.path.isdir(BAYESIAN_OPTS_DIR):\n",
    "    logging.info('Creating {} directory...'.format(BAYESIAN_OPTS_DIR))\n",
    "    os.mkdir(BAYESIAN_OPTS_DIR)\n",
    "\n",
    "if not os.path.isdir(BAYESIAN_OPTS_TEST_DIR):\n",
    "    logging.info('Creating {} directory...'.format(BAYESIAN_OPTS_TEST_DIR))\n",
    "    os.mkdir(BAYESIAN_OPTS_TEST_DIR)\n",
    "\n",
    "if not os.path.isdir(SUBMISSION_DIR):\n",
    "    logging.info('Creating {} directory...'.format(SUBMISSION_DIR))\n",
    "    os.mkdir(SUBMISSION_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_opt_verbose = False  # Flag for bayes-opt logging\n",
    "log_verbose = False  # Flag for miscellaneous log logging\n",
    "init_points = 2  # Number of random initialization rounds (30 used in winning submission)\n",
    "opt_iter = 2  # Number of bayesian optimization rounds (70 used in winning submission)\n",
    "\n",
    "num_gen_params =  2  # Number of top meta predictions to use for blending (20 used in winning submission)\n",
    "\n",
    "round_num = None  # Global variable to keep track of the bayesian optimization round\n",
    "is_training = None  # Global variable to indicate training or testing periods\n",
    "\n",
    "session = datetime.now()\n",
    "opt_val_seeds = get_opt_val_seeds(init_points * opt_iter)  # Generation of seeds for each bayesian optimization round\n",
    "\n",
    "model_set = ['lgb', 'lr', 'nn', 'xgb', 'rf']\n",
    "\n",
    "opt_res = {\n",
    "    'mwi': {},\n",
    "}\n",
    "\n",
    "country_preds_dict = {\n",
    "    'mwi': {},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute training and meta prediction inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fragment [1. Training bayesian opts for lgb model.] done in 35.26 s\n",
      "\n",
      "Fragment [2. Training bayesian opts for lr model.] done in 55.62 s\n",
      "\n",
      "Fragment [3. Training bayesian opts for nn model.] done in 43.26 s\n",
      "\n",
      "Fragment [4. Training bayesian opts for xgb model.] done in 182.21 s\n",
      "\n",
      "Fragment [5. Training bayesian opts for rf model.] done in 23.70 s\n",
      "\n",
      "Fragment [Start bayesian optimization and generation of optimal sub-models for country mwi] done in 340.05 s\n",
      "\n",
      "Fragment [1. Generating meta predictions for lgb model.] done in 17.91 s\n",
      "\n",
      "Fragment [2. Generating meta predictions for lr model.] done in 21.56 s\n",
      "\n",
      "Fragment [3. Generating meta predictions for nn model.] done in 12.58 s\n",
      "\n",
      "Fragment [4. Generating meta predictions for xgb model.] done in 146.08 s\n",
      "\n",
      "Fragment [5. Generating meta predictions for rf model.] done in 13.72 s\n",
      "\n",
      "Fragment [Generate inference using the top N models based on bayesian OOF score for country mwi] done in 211.86 s\n",
      "\n",
      "Fragment [Performing training and meta predictions for country mwi.] done in 553.10 s\n",
      "\n",
      "Fragment [Full model for all countries.] done in 553.10 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with timing('Full model for all countries.'):\n",
    "    for country_code in ['mwi']:\n",
    "        with timing('Performing training and meta predictions for country {}.'.format(country_code)):\n",
    "            x_model_train_preds = pd.DataFrame()\n",
    "            x_model_test_preds = pd.DataFrame()\n",
    "\n",
    "            _, indiv_train = load_data(country_code, data_part='train')\n",
    "\n",
    "            indiv_cat_train = pd.read_hdf(os.path.join(DATA_DIR, 'indiv_cat_train.hdf'), '{}_indiv_cat_train'.format(country_code))\n",
    "            indiv_cat_test = pd.read_hdf(os.path.join(DATA_DIR, 'indiv_cat_test.hdf'), '{}_indiv_cat_test'.format(country_code))\n",
    "\n",
    "            hhold_train = pd.read_csv(os.path.join(DATA_DIR, '{}-hhold-transformed-train.csv'.format(country_code)), index_col='id')\n",
    "            hhold_test = pd.read_csv(os.path.join(DATA_DIR, '{}-hhold-transformed-test.csv'.format(country_code)), index_col='id')\n",
    "\n",
    "            y_train = np.ravel(hhold_train.loc[indiv_cat_train.index].poor)\n",
    "\n",
    "            with timing('Start bayesian optimization and generation of optimal sub-models for country {}'.format(country_code)):\n",
    "                for ix, model_type in enumerate(model_set):\n",
    "                    with timing('{}. Training bayesian opts for {} model.'.format(ix + 1, model_type)):\n",
    "                        modelBO = bayesian_optimize_model(country_code=country_code, model_type=model_type, tunable_params=None, num_iter=opt_iter, init_points=init_points)\n",
    "                    opt_res[country_code][model_type] = modelBO.res\n",
    "\n",
    "            # Store optimization results\n",
    "            fname = os.path.join(BAYESIAN_OPTS_DIR, 'bayesian_opt_res-{}.pkl'.format(session))\n",
    "            vprint(fname)\n",
    "\n",
    "            with open(fname, 'wb') as fl:\n",
    "                cPickle.dump(opt_res, fl)\n",
    "\n",
    "            with timing('Generate inference using the top N models based on bayesian OOF score for country {}'.format(country_code)):\n",
    "                for ix, model_type in enumerate(model_set):\n",
    "                    with timing('{}. Generating meta predictions for {} model.'.format(ix + 1, model_type)):\n",
    "                        model_test_preds, model_train_preds = predict_from_opt(\n",
    "                            country_code, model_type, num_params=num_gen_params,\n",
    "                            use_latest=True, default_dir=BAYESIAN_OPTS_DIR\n",
    "                        )\n",
    "\n",
    "                        model_test_preds.to_hdf(\n",
    "                            os.path.join(BAYESIAN_OPTS_TEST_DIR, 'model_test_preds-{}.hdf'.format(session)),\n",
    "                            'model_test_preds_{}_{}'.format(country_code, model_type)\n",
    "                        )\n",
    "\n",
    "                        model_train_preds.to_hdf(\n",
    "                            os.path.join(BAYESIAN_OPTS_TEST_DIR, 'model_train_preds-{}.hdf'.format(session)),\n",
    "                            'model_train_preds{}_{}'.format(country_code, model_type)\n",
    "                        )\n",
    "\n",
    "                        # Collect meta predictions\n",
    "                        x_model_train_preds = pd.concat([x_model_train_preds, model_train_preds], axis=1)\n",
    "                        x_model_test_preds = pd.concat([x_model_test_preds, model_test_preds], axis=1)\n",
    "\n",
    "            country_preds_dict[country_code]['train'] = x_model_train_preds\n",
    "            country_preds_dict[country_code]['test'] = x_model_test_preds\n",
    "            country_preds_dict[country_code]['y_train'] = hhold_train.loc[x_model_train_preds.index].poor.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform OOF optimized blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2984074130677218\n",
      "0.2979799572477056\n",
      "0.30018553524182306\n",
      "0.3009378240836755\n",
      "0.30145900492820055\n",
      "0.30044315099320046\n",
      "0.29813375671015996\n",
      "0.29960457585837386\n",
      "0.2999125330821543\n",
      "0.2976273525330935\n",
      "0.29983243738230053 0.29948640458589687\n",
      "Fragment [Optimizing meta prediction weights for country mwi.] done in 3.66 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "median_weight_optimized_preds_sub = []\n",
    "mean_weight_optimized_preds_sub = []\n",
    "\n",
    "for country_code in ['mwi']:\n",
    "    with timing('Optimizing meta prediction weights for country {}.'.format(country_code)):\n",
    "        x_test_median_preds, x_test_mean_preds, x_optimized_weights_preds, x_coeffs = get_optimized_weighted_preds_for(country_preds_dict, country_code)\n",
    "\n",
    "    median_weight_optimized_preds_sub.append(make_country_sub(x_test_median_preds, x_test_median_preds, country_code))\n",
    "    mean_weight_optimized_preds_sub.append(make_country_sub(x_test_mean_preds, x_test_mean_preds, country_code))\n",
    "\n",
    "median_weight_optimized_preds_sub = pd.concat(median_weight_optimized_preds_sub)\n",
    "mean_weight_optimized_preds_sub = pd.concat(mean_weight_optimized_preds_sub)\n",
    "\n",
    "\n",
    "date_now = datetime.now()\n",
    "median_sub_fname = os.path.join(SUBMISSION_DIR, 'submission-test-median-agg-models-{}.csv'.format(date_now))\n",
    "mean_sub_fname = os.path.join(SUBMISSION_DIR, 'submission-test-mean-agg-models-{}.csv'.format(date_now))\n",
    "\n",
    "logging.info(median_sub_fname)\n",
    "logging.info(mean_sub_fname)\n",
    "\n",
    "median_weight_optimized_preds_sub.to_csv(median_sub_fname)\n",
    "mean_weight_optimized_preds_sub.to_csv(mean_sub_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "mwi    [[AxesSubplot(0.125,0.125;0.775x0.755)]]\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f94b9181b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "median_weight_optimized_preds_sub.groupby('country').hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "mwi    [[AxesSubplot(0.125,0.125;0.775x0.755)]]\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f94b88bf8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_weight_optimized_preds_sub.groupby('country').hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
